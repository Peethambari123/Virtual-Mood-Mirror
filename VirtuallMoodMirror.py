import streamlit as st
import numpy as np
import cv2
from deepface import DeepFace
import random

# Reactions dictionary
reactions = {
    "happy": ["ğŸ˜ƒ You look so happy! Here's a dancing cat GIF!", "ğŸ˜„ Keep smiling!"],
    "sad": ["ğŸ˜¢ Why are you crying?", "ğŸ¥º Want a virtual hug? ğŸ¤—"],
    "angry": ["ğŸ˜¡ Chill bro!", "ğŸ”¥ Take a deep breath!"],
    "neutral": ["ğŸ˜ Bruh...", "ğŸ«¤ Feeling meh?"]
}

st.set_page_config(page_title="Virtual Mood Mirror", layout="centered")
st.title("ğŸª Virtual Mood Mirror")
st.write("Take a photo and let me guess your mood!")

# Camera input
img_file_buffer = st.camera_input("ğŸ“¸ Take a photo")

if img_file_buffer is not None:
    # Convert image to OpenCV format
    file_bytes = np.asarray(bytearray(img_file_buffer.read()), dtype=np.uint8)
    frame = cv2.imdecode(file_bytes, 1)

    st.image(frame, caption="Your captured photo", channels="BGR")

    try:
        # Detect emotion
        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
        emotion = result[0]['dominant_emotion']
        st.subheader(f"ğŸ§  Detected Emotion: `{emotion}`")

        # Show response
        for key in reactions:
            if key in emotion.lower():
                st.success(random.choice(reactions[key]))
    except Exception as e:
        st.error("ğŸ™ Couldn't detect your face. Try again.")
